test_ops_xpu.py|_jiterator_ | Jiterator is only supported on CUDA and ROCm GPUs, none are available.; https://github.com/intel/torch-xpu-ops/issues/584
test_ops_xpu.py|test_errors_dot_xpu | OPs not supported
test_ops_xpu.py|test_errors_vdot_xpu | OPs not supported
test_ops_xpu.py|test_dtypes__refs_nn_functional_pdist_xpu | core dump
test_ops_xpu.py|test_python_ref_executor__refs_pow_executor_aten_xpu_complex32 | Reference result was farther (inf) from the precise; computation than the torch result was (nan)!
test_ops_xpu.py|test_python_ref_executor__refs_mul_executor_aten_xpu_complex32 | Reference result was farther (inf) from the precise; computation than the torch result was (nan)!
test_ops_xpu.py|histogramdd | https://github.com/intel/torch-xpu-ops/issues/2254
test_ops_xpu.py|_vdot_ | https://github.com/intel/torch-xpu-ops/issues/2254
test_ops_xpu.py|_dot_ | https://github.com/intel/torch-xpu-ops/issues/2254
test_ops_xpu.py|_flash_attention_ | https://github.com/intel/torch-xpu-ops/issues/2254
test_ops_xpu.py|_efficient_attention_ | https://github.com/intel/torch-xpu-ops/issues/2254
test_binary_ufuncs_xpu.py|test_fmod_remainder_by_zero_integral_xpu_int64 | zero division is an undefined behavior: different handles on different backends
test_binary_ufuncs_xpu.py|test_div_rounding_numpy_xpu_float16 | Calculation error. XPU implementation uses opmath type.
test_binary_ufuncs_xpu.py|_jiterator_ | AssertionError: Jiterator is only supported on CUDA and ROCm GPUs, none are available.
test_scatter_gather_ops_xpu.py|test_scatter_reduce_mean_xpu_float64 | AssertionError: Tensor-likes are not equal!; Mismatched elements: 2 / 1870 (0.1%); Greatest absolute difference: 2.220446049250313e-16 at index (14, 9, 4); Greatest relative difference: 1.7039539596977877e-16 at index (15, 7, 6)
test_sort_and_select_xpu.py|test_sort_large_slice_xpu | No reason provided
nn/test_embedding_xpu.py|test_embedding_bag_out_of_bounds_idx_padding_idx0_mode_max_xpu_float32_int32 | CUDA implementation has no such functionality due to performance consideration.; skipped by CUDA for performance; @skipCUDAIf(True, "no out-of-bounds check on CUDA for perf.")
nn/test_embedding_xpu.py|test_embedding_bag_out_of_bounds_idx_padding_idx0_mode_max_xpu_float32_int64 | CUDA implementation has no such functionality due to performance consideration.; skipped by CUDA for performance; @skipCUDAIf(True, "no out-of-bounds check on CUDA for perf.")
nn/test_embedding_xpu.py|test_embedding_bag_out_of_bounds_idx_padding_idx0_mode_max_xpu_float64_int32 | CUDA implementation has no such functionality due to performance consideration.; skipped by CUDA for performance; @skipCUDAIf(True, "no out-of-bounds check on CUDA for perf.")
nn/test_embedding_xpu.py|test_embedding_bag_out_of_bounds_idx_padding_idx0_mode_max_xpu_float64_int64 | CUDA implementation has no such functionality due to performance consideration.; skipped by CUDA for performance; @skipCUDAIf(True, "no out-of-bounds check on CUDA for perf.")
nn/test_embedding_xpu.py|test_embedding_bag_out_of_bounds_idx_padding_idx0_mode_mean_xpu_float32_int32 | CUDA implementation has no such functionality due to performance consideration.; skipped by CUDA for performance; @skipCUDAIf(True, "no out-of-bounds check on CUDA for perf.")
nn/test_embedding_xpu.py|test_embedding_bag_out_of_bounds_idx_padding_idx0_mode_mean_xpu_float32_int64 | CUDA implementation has no such functionality due to performance consideration.; skipped by CUDA for performance; @skipCUDAIf(True, "no out-of-bounds check on CUDA for perf.")
nn/test_embedding_xpu.py|test_embedding_bag_out_of_bounds_idx_padding_idx0_mode_mean_xpu_float64_int32 | CUDA implementation has no such functionality due to performance consideration.; skipped by CUDA for performance; @skipCUDAIf(True, "no out-of-bounds check on CUDA for perf.")
nn/test_embedding_xpu.py|test_embedding_bag_out_of_bounds_idx_padding_idx0_mode_mean_xpu_float64_int64 | CUDA implementation has no such functionality due to performance consideration.; skipped by CUDA for performance; @skipCUDAIf(True, "no out-of-bounds check on CUDA for perf.")
nn/test_embedding_xpu.py|test_embedding_bag_out_of_bounds_idx_padding_idx0_mode_sum_xpu_float32_int32 | CUDA implementation has no such functionality due to performance consideration.; skipped by CUDA for performance; @skipCUDAIf(True, "no out-of-bounds check on CUDA for perf.")
nn/test_embedding_xpu.py|test_embedding_bag_out_of_bounds_idx_padding_idx0_mode_sum_xpu_float32_int64 | CUDA implementation has no such functionality due to performance consideration.; skipped by CUDA for performance; @skipCUDAIf(True, "no out-of-bounds check on CUDA for perf.")
nn/test_embedding_xpu.py|test_embedding_bag_out_of_bounds_idx_padding_idx0_mode_sum_xpu_float64_int32 | CUDA implementation has no such functionality due to performance consideration.; skipped by CUDA for performance; @skipCUDAIf(True, "no out-of-bounds check on CUDA for perf.")
nn/test_embedding_xpu.py|test_embedding_bag_out_of_bounds_idx_padding_idx0_mode_sum_xpu_float64_int64 | CUDA implementation has no such functionality due to performance consideration.; skipped by CUDA for performance; @skipCUDAIf(True, "no out-of-bounds check on CUDA for perf.")
nn/test_embedding_xpu.py|test_embedding_bag_out_of_bounds_idx_padding_idx_0_mode_max_xpu_float32_int32 | CUDA implementation has no such functionality due to performance consideration.; skipped by CUDA for performance; @skipCUDAIf(True, "no out-of-bounds check on CUDA for perf.")
nn/test_embedding_xpu.py|test_embedding_bag_out_of_bounds_idx_padding_idx_0_mode_max_xpu_float32_int64 | CUDA implementation has no such functionality due to performance consideration.; skipped by CUDA for performance; @skipCUDAIf(True, "no out-of-bounds check on CUDA for perf.")
nn/test_embedding_xpu.py|test_embedding_bag_out_of_bounds_idx_padding_idx_0_mode_max_xpu_float64_int32 | CUDA implementation has no such functionality due to performance consideration.; skipped by CUDA for performance; @skipCUDAIf(True, "no out-of-bounds check on CUDA for perf.")
nn/test_embedding_xpu.py|test_embedding_bag_out_of_bounds_idx_padding_idx_0_mode_max_xpu_float64_int64 | CUDA implementation has no such functionality due to performance consideration.; skipped by CUDA for performance; @skipCUDAIf(True, "no out-of-bounds check on CUDA for perf.")
nn/test_embedding_xpu.py|test_embedding_bag_out_of_bounds_idx_padding_idx_0_mode_mean_xpu_float32_int32 | CUDA implementation has no such functionality due to performance consideration.; skipped by CUDA for performance; @skipCUDAIf(True, "no out-of-bounds check on CUDA for perf.")
nn/test_embedding_xpu.py|test_embedding_bag_out_of_bounds_idx_padding_idx_0_mode_mean_xpu_float32_int64 | CUDA implementation has no such functionality due to performance consideration.; skipped by CUDA for performance; @skipCUDAIf(True, "no out-of-bounds check on CUDA for perf.")
nn/test_embedding_xpu.py|test_embedding_bag_out_of_bounds_idx_padding_idx_0_mode_mean_xpu_float64_int32 | CUDA implementation has no such functionality due to performance consideration.; skipped by CUDA for performance; @skipCUDAIf(True, "no out-of-bounds check on CUDA for perf.")
nn/test_embedding_xpu.py|test_embedding_bag_out_of_bounds_idx_padding_idx_0_mode_mean_xpu_float64_int64 | CUDA implementation has no such functionality due to performance consideration.; skipped by CUDA for performance; @skipCUDAIf(True, "no out-of-bounds check on CUDA for perf.")
nn/test_embedding_xpu.py|test_embedding_bag_out_of_bounds_idx_padding_idx_0_mode_sum_xpu_float32_int32 | CUDA implementation has no such functionality due to performance consideration.; skipped by CUDA for performance; @skipCUDAIf(True, "no out-of-bounds check on CUDA for perf.")
nn/test_embedding_xpu.py|test_embedding_bag_out_of_bounds_idx_padding_idx_0_mode_sum_xpu_float32_int64 | CUDA implementation has no such functionality due to performance consideration.; skipped by CUDA for performance; @skipCUDAIf(True, "no out-of-bounds check on CUDA for perf.")
nn/test_embedding_xpu.py|test_embedding_bag_out_of_bounds_idx_padding_idx_0_mode_sum_xpu_float64_int32 | CUDA implementation has no such functionality due to performance consideration.; skipped by CUDA for performance; @skipCUDAIf(True, "no out-of-bounds check on CUDA for perf.")
nn/test_embedding_xpu.py|test_embedding_bag_out_of_bounds_idx_padding_idx_0_mode_sum_xpu_float64_int64 | CUDA implementation has no such functionality due to performance consideration.; skipped by CUDA for performance; @skipCUDAIf(True, "no out-of-bounds check on CUDA for perf.")
test_transformers_xpu.py|test_mem_eff_attention_large_seq_len_uniform_attention_xpu | Efficient attention is not supported.
test_transformers_xpu.py|test_mem_eff_attention_fail_with_batch_size_geq_65536 | AssertionError("Torch not compiled with CUDA enabled")
test_transformers_xpu.py|test_disable_fastpath_xpu | https://github.com/intel/torch-xpu-ops/issues/761; AssertionError: False is not true; CPU fallback failure. To support aten::transformer_encoder_layer_forward with proper priority.
test_transformers_xpu.py|test_with_nested_tensor_input_xpu | NestedTensorXPU not supported; Could not run 'aten::_to_copy' with arguments from the 'NestedTensorXPU' backend
test_transformers_xpu.py|test_scaled_dot_product_attention_4D_input_dim_no_attn_mask_dropout_p_0_2_xpu | oneDNN issues; Double and complex datatype matmul is not supported in oneDNN; https://github.com/intel/torch-xpu-ops/issues/253
test_transformers_xpu.py|test_scaled_dot_product_attention_4D_input_dim_4D_causal_attn_mask_dropout_p_0_5_xpu | oneDNN issues; Double and complex datatype matmul is not supported in oneDNN; https://github.com/intel/torch-xpu-ops/issues/253
test_transformers_xpu.py|test_scaled_dot_product_attention_4D_input_dim_4D_causal_attn_mask_dropout_p_0_2_xpu | oneDNN issues; Double and complex datatype matmul is not supported in oneDNN; https://github.com/intel/torch-xpu-ops/issues/253
test_transformers_xpu.py|test_scaled_dot_product_attention_4D_input_dim_2D_causal_attn_mask_dropout_p_0_5_xpu | oneDNN issues; Double and complex datatype matmul is not supported in oneDNN; https://github.com/intel/torch-xpu-ops/issues/253
test_transformers_xpu.py|test_scaled_dot_product_attention_4D_input_dim_2D_causal_attn_mask_dropout_p_0_2_xpu | oneDNN issues; Double and complex datatype matmul is not supported in oneDNN; https://github.com/intel/torch-xpu-ops/issues/253
test_transformers_xpu.py|test_scaled_dot_product_attention_4D_input_dim_2D_attn_mask_dropout_p_0_5_xpu | oneDNN issues; Double and complex datatype matmul is not supported in oneDNN; https://github.com/intel/torch-xpu-ops/issues/253
test_transformers_xpu.py|test_scaled_dot_product_attention_4D_input_dim_2D_attn_mask_dropout_p_0_2_xpu | oneDNN issues; Double and complex datatype matmul is not supported in oneDNN; https://github.com/intel/torch-xpu-ops/issues/253
test_transformers_xpu.py|test_scaled_dot_product_attention_3D_input_dim_no_attn_mask_dropout_p_0_5_xpu | oneDNN issues; Double and complex datatype matmul is not supported in oneDNN; https://github.com/intel/torch-xpu-ops/issues/253
test_transformers_xpu.py|test_scaled_dot_product_attention_3D_input_dim_no_attn_mask_dropout_p_0_2_xpu | oneDNN issues; Double and complex datatype matmul is not supported in oneDNN; https://github.com/intel/torch-xpu-ops/issues/253
test_transformers_xpu.py|test_scaled_dot_product_attention_3D_input_dim_3D_causal_attn_mask_dropout_p_0_5_xpu | oneDNN issues; Double and complex datatype matmul is not supported in oneDNN; https://github.com/intel/torch-xpu-ops/issues/253
test_transformers_xpu.py|test_scaled_dot_product_attention_3D_input_dim_3D_causal_attn_mask_dropout_p_0_2_xpu | oneDNN issues; Double and complex datatype matmul is not supported in oneDNN; https://github.com/intel/torch-xpu-ops/issues/253
test_transformers_xpu.py|test_scaled_dot_product_attention_3D_input_dim_2D_causal_attn_mask_dropout_p_0_5_xpu | oneDNN issues; Double and complex datatype matmul is not supported in oneDNN; https://github.com/intel/torch-xpu-ops/issues/253
test_transformers_xpu.py|test_scaled_dot_product_attention_3D_input_dim_2D_causal_attn_mask_dropout_p_0_2_xpu | oneDNN issues; Double and complex datatype matmul is not supported in oneDNN; https://github.com/intel/torch-xpu-ops/issues/253
test_transformers_xpu.py|test_scaled_dot_product_attention_3D_input_dim_2D_attn_mask_dropout_p_0_5_xpu | oneDNN issues; Double and complex datatype matmul is not supported in oneDNN; https://github.com/intel/torch-xpu-ops/issues/253
test_transformers_xpu.py|test_scaled_dot_product_attention_3D_input_dim_2D_attn_mask_dropout_p_0_2_xpu | oneDNN issues; Double and complex datatype matmul is not supported in oneDNN; https://github.com/intel/torch-xpu-ops/issues/253
test_modules_xpu.py|test_grad_nn_MultiheadAttention_eval_mode_xpu_float64 | oneDNN issues; RuntimeError: Double and complex datatype matmul is not supported in oneDNN
test_modules_xpu.py|test_grad_nn_MultiheadAttention_train_mode_xpu_float64 | oneDNN issues; RuntimeError: Double and complex datatype matmul is not supported in oneDNN
test_modules_xpu.py|test_gradgrad_nn_MultiheadAttention_eval_mode_xpu_float64 | oneDNN issues; RuntimeError: Double and complex datatype matmul is not supported in oneDNN
test_modules_xpu.py|test_gradgrad_nn_MultiheadAttention_train_mode_xpu_float64 | oneDNN issues; RuntimeError: Double and complex datatype matmul is not supported in oneDNN
test_modules_xpu.py|test_cpu_gpu_parity_nn_ConvTranspose1d_xpu_complex32 | Unexpected success:
test_modules_xpu.py|test_cpu_gpu_parity_nn_ConvTranspose2d_xpu_complex32 | Unexpected success:
test_modules_xpu.py|test_to_nn_BatchNorm1d_eval_mode_swap_True_set_grad_True_xpu_float32 | CPU fallback fails; RuntimeError: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.; AssertionError: False is not true
test_modules_xpu.py|test_to_nn_BatchNorm1d_train_mode_swap_True_set_grad_True_xpu_float32 | CPU fallback fails; RuntimeError: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.; AssertionError: False is not true
test_modules_xpu.py|test_to_nn_BatchNorm2d_eval_mode_swap_True_set_grad_True_xpu_float32 | CPU fallback fails; RuntimeError: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.; AssertionError: False is not true
test_modules_xpu.py|test_to_nn_BatchNorm2d_train_mode_swap_True_set_grad_True_xpu_float32 | CPU fallback fails; RuntimeError: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.; AssertionError: False is not true
test_modules_xpu.py|test_to_nn_BatchNorm3d_eval_mode_swap_True_set_grad_True_xpu_float32 | CPU fallback fails; RuntimeError: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.; AssertionError: False is not true
test_modules_xpu.py|test_to_nn_BatchNorm3d_train_mode_swap_True_set_grad_True_xpu_float32 | CPU fallback fails; RuntimeError: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.; AssertionError: False is not true
test_modules_xpu.py|test_to_nn_Bilinear_swap_True_set_grad_True_xpu_float32 | CPU fallback fails; RuntimeError: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.; AssertionError: False is not true
test_modules_xpu.py|test_to_nn_Conv1d_swap_True_set_grad_True_xpu_float32 | CPU fallback fails; RuntimeError: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.; AssertionError: False is not true
test_modules_xpu.py|test_to_nn_Conv2d_swap_True_set_grad_True_xpu_float32 | CPU fallback fails; RuntimeError: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.; AssertionError: False is not true
test_modules_xpu.py|test_to_nn_Conv3d_swap_True_set_grad_True_xpu_float32 | CPU fallback fails; RuntimeError: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.; AssertionError: False is not true
test_modules_xpu.py|test_to_nn_ConvTranspose1d_swap_True_set_grad_True_xpu_float32 | CPU fallback fails; RuntimeError: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.; AssertionError: False is not true
test_modules_xpu.py|test_to_nn_ConvTranspose2d_swap_True_set_grad_True_xpu_float32 | CPU fallback fails; RuntimeError: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.; AssertionError: False is not true
test_modules_xpu.py|test_to_nn_ConvTranspose3d_swap_True_set_grad_True_xpu_float32 | CPU fallback fails; RuntimeError: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.; AssertionError: False is not true
test_modules_xpu.py|test_to_nn_Embedding_swap_True_set_grad_True_xpu_float32 | CPU fallback fails; RuntimeError: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.; AssertionError: False is not true
test_modules_xpu.py|test_to_nn_GRUCell_swap_True_set_grad_True_xpu_float32 | CPU fallback fails; RuntimeError: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.; AssertionError: False is not true
test_modules_xpu.py|test_to_nn_GRU_eval_mode_swap_True_set_grad_True_xpu_float32 | CPU fallback fails; RuntimeError: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.; AssertionError: False is not true
test_modules_xpu.py|test_to_nn_GRU_train_mode_swap_True_set_grad_True_xpu_float32 | CPU fallback fails; RuntimeError: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.; AssertionError: False is not true
test_modules_xpu.py|test_to_nn_GroupNorm_swap_True_set_grad_True_xpu_float32 | CPU fallback fails; RuntimeError: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.; AssertionError: False is not true
test_modules_xpu.py|test_to_nn_LSTMCell_swap_True_set_grad_True_xpu_float32 | CPU fallback fails; RuntimeError: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.; AssertionError: False is not true
test_modules_xpu.py|test_to_nn_LSTM_eval_mode_swap_True_set_grad_True_xpu_float32 | CPU fallback fails; RuntimeError: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.; AssertionError: False is not true
test_modules_xpu.py|test_to_nn_LSTM_train_mode_swap_True_set_grad_True_xpu_float32 | CPU fallback fails; RuntimeError: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.; AssertionError: False is not true
test_modules_xpu.py|test_to_nn_LayerNorm_swap_True_set_grad_True_xpu_float32 | CPU fallback fails; RuntimeError: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.; AssertionError: False is not true
test_modules_xpu.py|test_to_nn_Linear_swap_True_set_grad_True_xpu_float32 | CPU fallback fails; RuntimeError: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.; AssertionError: False is not true
test_modules_xpu.py|test_to_nn_MultiheadAttention_eval_mode_swap_True_set_grad_True_xpu_float32 | CPU fallback fails; RuntimeError: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.; AssertionError: False is not true
test_modules_xpu.py|test_to_nn_MultiheadAttention_train_mode_swap_True_set_grad_True_xpu_float32 | CPU fallback fails; RuntimeError: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.; AssertionError: False is not true
test_modules_xpu.py|test_to_nn_PReLU_swap_True_set_grad_True_xpu_float32 | CPU fallback fails; RuntimeError: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.; AssertionError: False is not true
test_modules_xpu.py|test_to_nn_RMSNorm_swap_True_set_grad_True_xpu_float32 | CPU fallback fails; RuntimeError: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.; AssertionError: False is not true
test_modules_xpu.py|test_to_nn_RNNCell_swap_True_set_grad_True_xpu_float32 | CPU fallback fails; RuntimeError: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.; AssertionError: False is not true
test_modules_xpu.py|test_to_nn_RNN_eval_mode_swap_True_set_grad_True_xpu_float32 | CPU fallback fails; RuntimeError: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.; AssertionError: False is not true
test_modules_xpu.py|test_to_nn_RNN_train_mode_swap_True_set_grad_True_xpu_float32 | CPU fallback fails; RuntimeError: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.; AssertionError: False is not true
test_modules_xpu.py|test_to_nn_TransformerDecoderLayer_swap_True_set_grad_True_xpu_float32 | CPU fallback fails; RuntimeError: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.; AssertionError: False is not true
test_modules_xpu.py|test_to_nn_TransformerEncoderLayer_eval_mode_swap_True_set_grad_True_xpu_float32 | CPU fallback fails; RuntimeError: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.; AssertionError: False is not true
test_modules_xpu.py|test_to_nn_TransformerEncoderLayer_train_mode_swap_True_set_grad_True_xpu_float32 | CPU fallback fails; RuntimeError: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.; AssertionError: False is not true
test_modules_xpu.py|test_to_nn_TransformerEncoder_eval_mode_swap_True_set_grad_True_xpu_float32 | CPU fallback fails; RuntimeError: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.; AssertionError: False is not true
test_modules_xpu.py|test_to_nn_TransformerEncoder_train_mode_swap_True_set_grad_True_xpu_float32 | CPU fallback fails; RuntimeError: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.; AssertionError: False is not true
test_modules_xpu.py|test_to_nn_Transformer_swap_True_set_grad_True_xpu_float32 | CPU fallback fails; RuntimeError: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.; AssertionError: False is not true
test_modules_xpu.py|test_memory_format_nn_Conv2d_xpu_float64 | Unexpected succuss
test_modules_xpu.py|test_memory_format_nn_ConvTranspose2d_xpu_float64 | Unexpected succuss
test_modules_xpu.py|test_memory_format_nn_LazyConv2d_xpu_float64 | Unexpected succuss
test_modules_xpu.py|test_memory_format_nn_LazyConvTranspose2d_xpu_float64 | Unexpected succuss
test_nn_xpu.py|test_type | AttributeError: module 'torch.xpu' has no attribute 'FloatTensor'
test_nn_xpu.py|test_cudnn_weight_format | rnn fallback to cpu
test_nn_xpu.py|test_TransformerEncoderLayer_empty_xpu | oneDNN issues; AssertionError: MultiheadAttention does not support NestedTensor outside of its fast path. The fast path was not hit because some Tensor argument's device is neither one of cpu, cuda or privateuseone
test_nn_xpu.py|test_transformerencoderlayer_xpu_float16 | oneDNN issues; AssertionError: MultiheadAttention does not support NestedTensor outside of its fast path. The fast path was not hit because some Tensor argument's device is neither one of cpu, cuda or privateuseone
test_nn_xpu.py|test_transformerencoderlayer_xpu_float32 | oneDNN issues; AssertionError: MultiheadAttention does not support NestedTensor outside of its fast path. The fast path was not hit because some Tensor argument's device is neither one of cpu, cuda or privateuseone
test_nn_xpu.py|test_transformerencoderlayer_xpu_float64 | oneDNN issues; RuntimeError: Double and complex datatype matmul is not supported in oneDNN
test_nn_xpu.py|test_upsamplingNearest2d_launch_fail_xpu | Unexpected success: CUDA only test case, launch grid_y == 2**16 (larger than CUDA maximum y-dimension limit 65535) and expect fail.; SYCL don't have this limitation and hence can pass.
test_nn_xpu.py|test_ctc_loss_cudnn_xpu | want "xpu" in function name
test_nn_xpu.py|test_ctc_loss_cudnn_tensor | want "xpu" in function name
test_nn_xpu.py|test_ReflectionPad2d_large_deterministic_xpu | RuntimeError: reflection_pad2d_backward_xpu does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True)'.
test_nn_xpu.py|test_layer_norm_backwards_eps | x_cuda = x.clone().detach().to("cuda").requires_grad_(): Torch not compiled with CUDA enabled
test_autograd_xpu.py|test_profiler_emit_nvtx_xpu | AttributeError: module 'torch.xpu' has no attribute
test_autograd_xpu.py|test_mv_grad_stride_0_xpu | Double and complex datatype matmul is not supported in oneDNN
test_autograd_xpu.py|test_checkpointing_without_reentrant_dataparallel | module 'torch._C' has no attribute '_scatter'
test_autograd_xpu.py|test_dataparallel_saved_tensors_hooks | module 'torch._C' has no attribute '_scatter'
test_view_ops_xpu.py|test_flatten_xpu | Need quantization support, NotImplementedError: Could not run 'aten::_empty_affine_quantized' with arguments from the 'QuantizedXPU' backend.
test_view_ops_xpu.py|test_ravel_xpu | Need quantization support, NotImplementedError: Could not run 'aten::_empty_affine_quantized' with arguments from the 'QuantizedXPU' backend.
test_shape_ops_xpu.py|test_flip_xpu_float32 | Need quantization support.; https://github.com/intel/torch-xpu-ops/issues/275; NotImplementedError: Could not run 'aten::empty_quantized' with arguments from the 'QuantizedXPU' backend.
test_linalg_xpu.py|test_tensordot_out_kernel_errors_with_autograd_xpu_float32 | Summary:; RuntimeError: Double and complex datatype matmul is not supported in oneDNN
test_linalg_xpu.py|test_addmm_gelu_xpu_float64 | Summary:; RuntimeError: Double and complex datatype matmul is not supported in oneDNN
test_linalg_xpu.py|test_addmm_relu_xpu_float64 | Summary:; RuntimeError: Double and complex datatype matmul is not supported in oneDNN
test_linalg_xpu.py|test_addmm_sizes_xpu_float64 | Summary:; RuntimeError: Double and complex datatype matmul is not supported in oneDNN
test_linalg_xpu.py|test_addmm_xpu_float64 | Summary:; RuntimeError: Double and complex datatype matmul is not supported in oneDNN
test_linalg_xpu.py|test_baddbmm_xpu_float64 | Summary:; RuntimeError: Double and complex datatype matmul is not supported in oneDNN
test_linalg_xpu.py|test_einsum_random_xpu_float64 | Summary:; RuntimeError: Double and complex datatype matmul is not supported in oneDNN
test_linalg_xpu.py|test_lobpcg_basic_xpu_float64 | Summary:; RuntimeError: Double and complex datatype matmul is not supported in oneDNN
test_linalg_xpu.py|test_lobpcg_ortho_xpu_float64 | Summary:; RuntimeError: Double and complex datatype matmul is not supported in oneDNN
test_linalg_xpu.py|test_pca_lowrank_xpu | Summary:; RuntimeError: Double and complex datatype matmul is not supported in oneDNN
test_linalg_xpu.py|test_svd_lowrank_xpu_float64 | Summary:; RuntimeError: Double and complex datatype matmul is not supported in oneDNN
test_linalg_xpu.py|test_linalg_lstsq_input_checks_xpu_float32 | Summary:; RuntimeError: Double and complex datatype matmul is not supported in oneDNN
test_linalg_xpu.py|test_linalg_lstsq_input_checks_xpu_float64 | Summary:; RuntimeError: Double and complex datatype matmul is not supported in oneDNN
test_linalg_xpu.py|test_dot_invalid_args_xpu | Summary:; RuntimeError: Double and complex datatype matmul is not supported in oneDNN
test_linalg_xpu.py|test_vdot_invalid_args_xpu | Summary:; RuntimeError: Double and complex datatype matmul is not supported in oneDNN
test_linalg_xpu.py|test__int_mm_errors_xpu | Summary:; RuntimeError: Double and complex datatype matmul is not supported in oneDNN
test_linalg_xpu.py|_tunableop_ | https://github.com/intel/torch-xpu-ops/issues/814; xpu does not have '_cuda_tunableop_is_enabled' API
test_linalg_xpu.py|test_matmul_small_brute_force_tunableop_xpu_float16 | https://github.com/intel/torch-xpu-ops/issues/814; xpu does not have '_cuda_tunableop_is_enabled' API
test_linalg_xpu.py|test_matmul_small_brute_force_tunableop_xpu_float32 | https://github.com/intel/torch-xpu-ops/issues/814; xpu does not have '_cuda_tunableop_is_enabled' API
test_linalg_xpu.py|test_matmul_small_brute_force_tunableop_xpu_float64 | https://github.com/intel/torch-xpu-ops/issues/814; xpu does not have '_cuda_tunableop_is_enabled' API
test_linalg_xpu.py|test_matmul_offline_tunableop_xpu_float16 | https://github.com/intel/torch-xpu-ops/issues/814; xpu does not have '_cuda_tunableop_is_enabled' API
test_linalg_xpu.py|test_bmm_tunableop_rocm_xpu_float32 | XPU does not support tunable.
test_linalg_xpu.py|test_numeric_check_leak_tunableop_rocm_xpu_float32 | XPU does not support tunable.
test_linalg_xpu.py|test_dump_results_on_exit_tunableop_xpu_float32 | XPU does not support tunable.
test_linalg_xpu.py|test_rotating_buffer_tunableop_xpu_float32 | XPU does not support tunable.
test_linalg_xpu.py|test_gemm_bias_tunableop_xpu_bfloat16 | XPU does not support tunable.
test_linalg_xpu.py|test_scaled_gemm_tunableop_xpu_float8_e4m3fnuz | XPU does not support tunable.
test_linalg_xpu.py|test_scaled_gemm_tunableop_xpu_float8_e5m2fnuz | XPU does not support tunable.
test_linalg_xpu.py|test_matmul_check_entries_tunableop_xpu_float16 | CUDA bias cases added in latest PyTorch; AttributeError: module 'torch._C' has no attribute '_cuda_tunableop_enable'; https://github.com/intel/torch-xpu-ops/issues/2066
test_linalg_xpu.py|test_minimum_tuning_iteration_tunableop_xpu_float16 | CUDA bias cases added in latest PyTorch; AttributeError: module 'torch._C' has no attribute '_cuda_tunableop_enable'; https://github.com/intel/torch-xpu-ops/issues/2066
test_linalg_xpu.py|test_validator_tunableop_rocm_xpu_float32 | CUDA bias cases added in latest PyTorch; AttributeError: module 'torch._C' has no attribute '_cuda_tunableop_enable'; https://github.com/intel/torch-xpu-ops/issues/2066
test_linalg_xpu.py|test_addmm_relu_tunableop_rocm_xpu_float32 | CUDA bias cases added in latest PyTorch; AttributeError: module 'torch._C' has no attribute '_cuda_tunableop_enable'; https://github.com/intel/torch-xpu-ops/issues/2066
test_linalg_xpu.py|test_addmm_relu_tunableop_rocm_xpu_float64 | CUDA bias cases added in latest PyTorch; AttributeError: module 'torch._C' has no attribute '_cuda_tunableop_enable'; https://github.com/intel/torch-xpu-ops/issues/2066
test_linalg_xpu.py|_tuning_tunableop_ | CUDA bias cases added in latest PyTorch; AttributeError: module 'torch._C' has no attribute '_cuda_tunableop_enable'; https://github.com/intel/torch-xpu-ops/issues/2066
test_linalg_xpu.py|test__int4_mm_m_32_k_32_n_48_xpu | TODO: align input data type for convert_weight_to_int4pack with CUDA; XPU expects weight to be kInt, while CUDA expects kByte
test_linalg_xpu.py|test__int4_mm_m_32_k_64_n_48_xpu | TODO: align input data type for convert_weight_to_int4pack with CUDA; XPU expects weight to be kInt, while CUDA expects kByte
test_linalg_xpu.py|test__int4_mm_m_64_k_32_n_48_xpu | TODO: align input data type for convert_weight_to_int4pack with CUDA; XPU expects weight to be kInt, while CUDA expects kByte
test_linalg_xpu.py|test__int4_mm_m_64_k_32_n_64_xpu | TODO: align input data type for convert_weight_to_int4pack with CUDA; XPU expects weight to be kInt, while CUDA expects kByte
test_linalg_xpu.py|test__int4_mm_m_64_k_64_n_48_xpu | TODO: align input data type for convert_weight_to_int4pack with CUDA; XPU expects weight to be kInt, while CUDA expects kByte
test_linalg_xpu.py|test__int4_mm_m_64_k_64_n_64_xpu | TODO: align input data type for convert_weight_to_int4pack with CUDA; XPU expects weight to be kInt, while CUDA expects kByte
test_linalg_xpu.py|test_compile_int4_mm_m_32_k_32_n_48_xpu | TODO: align input data type for convert_weight_to_int4pack with CUDA; XPU expects weight to be kInt, while CUDA expects kByte
test_linalg_xpu.py|test_compile_int4_mm_m_32_k_32_n_64_xpu | TODO: align input data type for convert_weight_to_int4pack with CUDA; XPU expects weight to be kInt, while CUDA expects kByte
test_linalg_xpu.py|test_compile_int4_mm_m_32_k_64_n_48_xpu | TODO: align input data type for convert_weight_to_int4pack with CUDA; XPU expects weight to be kInt, while CUDA expects kByte
test_linalg_xpu.py|test_compile_int4_mm_m_32_k_64_n_64_xpu | TODO: align input data type for convert_weight_to_int4pack with CUDA; XPU expects weight to be kInt, while CUDA expects kByte
test_linalg_xpu.py|test_compile_int4_mm_m_64_k_32_n_48_xpu | TODO: align input data type for convert_weight_to_int4pack with CUDA; XPU expects weight to be kInt, while CUDA expects kByte
test_linalg_xpu.py|test_compile_int4_mm_m_64_k_32_n_64_xpu | TODO: align input data type for convert_weight_to_int4pack with CUDA; XPU expects weight to be kInt, while CUDA expects kByte
test_linalg_xpu.py|test_compile_int4_mm_m_64_k_64_n_48_xpu | TODO: align input data type for convert_weight_to_int4pack with CUDA; XPU expects weight to be kInt, while CUDA expects kByte
test_linalg_xpu.py|test_compile_int4_mm_m_64_k_64_n_64_xpu | TODO: align input data type for convert_weight_to_int4pack with CUDA; XPU expects weight to be kInt, while CUDA expects kByte
test_linalg_xpu.py|test_matmul_scaled_gemm_offline_tunableop_xpu_float8_e4m3fnuz | float8 is not supported
test_linalg_xpu.py|test_matmul_scaled_gemm_offline_tunableop_xpu_float8_e5m2fnuz | float8 is not supported
test_linalg_xpu.py|test_scaled_gemm_offline_tunableop_xpu_float8_e4m3fnuz | float8 is not supported
test_linalg_xpu.py|test_scaled_gemm_offline_tunableop_xpu_float8_e5m2fnuz | float8 is not supported
test_linalg_xpu.py|test_gemm_bias_offline_tunableop_xpu_bfloat16 | case need to port for xpu
test_linalg_xpu.py|test_inv_errors_and_warnings_xpu_float32 | Exception is temporarily unavailable due to regression in oneMKL
test_linalg_xpu.py|test_inv_errors_and_warnings_xpu_float64 | Exception is temporarily unavailable due to regression in oneMKL
test_linalg_xpu.py|test_inverse_errors_large_xpu_float32 | Exception is temporarily unavailable due to regression in oneMKL
test_linalg_xpu.py|test_inverse_errors_large_xpu_float64 | Exception is temporarily unavailable due to regression in oneMKL
test_linalg_xpu.py|test_inverse_errors_xpu_float32 | Exception is temporarily unavailable due to regression in oneMKL
test_linalg_xpu.py|test_inverse_errors_xpu_float64 | Exception is temporarily unavailable due to regression in oneMKL
test_linalg_xpu.py|test_inv_ex_singular_xpu_float32 | Exception is temporarily unavailable due to regression in oneMKL
test_linalg_xpu.py|test_inv_ex_singular_xpu_float64 | Exception is temporarily unavailable due to regression in oneMKL
test_ops_fwd_gradients_xpu.py|test_fn_fwgrad_bwgrad___rmatmul___xpu_float64 | All of the followings are oneDNN issues; RuntimeError: Double and complex datatype matmul is not supported in oneDNN
test_ops_fwd_gradients_xpu.py|test_fn_fwgrad_bwgrad_addmv_xpu_float64 | All of the followings are oneDNN issues; RuntimeError: Double and complex datatype matmul is not supported in oneDNN
test_ops_fwd_gradients_xpu.py|test_fn_fwgrad_bwgrad_addr_xpu_float64 | All of the followings are oneDNN issues; RuntimeError: Double and complex datatype matmul is not supported in oneDNN
test_ops_fwd_gradients_xpu.py|test_fn_fwgrad_bwgrad_matmul_xpu_float64 | All of the followings are oneDNN issues; RuntimeError: Double and complex datatype matmul is not supported in oneDNN
test_ops_fwd_gradients_xpu.py|test_fn_fwgrad_bwgrad_mv_xpu_float64 | All of the followings are oneDNN issues; RuntimeError: Double and complex datatype matmul is not supported in oneDNN
test_ops_fwd_gradients_xpu.py|test_forward_mode_AD___rmatmul___xpu_float64 | All of the followings are oneDNN issues; RuntimeError: Double and complex datatype matmul is not supported in oneDNN
test_ops_fwd_gradients_xpu.py|test_forward_mode_AD_addbmm_xpu_float64 | All of the followings are oneDNN issues; RuntimeError: Double and complex datatype matmul is not supported in oneDNN
test_ops_fwd_gradients_xpu.py|test_forward_mode_AD_addmm_xpu_float64 | All of the followings are oneDNN issues; RuntimeError: Double and complex datatype matmul is not supported in oneDNN
test_ops_fwd_gradients_xpu.py|test_forward_mode_AD_addmv_xpu_float64 | All of the followings are oneDNN issues; RuntimeError: Double and complex datatype matmul is not supported in oneDNN
test_ops_fwd_gradients_xpu.py|test_forward_mode_AD_baddbmm_xpu_float64 | All of the followings are oneDNN issues; RuntimeError: Double and complex datatype matmul is not supported in oneDNN
test_ops_fwd_gradients_xpu.py|test_forward_mode_AD_matmul_xpu_float64 | All of the followings are oneDNN issues; RuntimeError: Double and complex datatype matmul is not supported in oneDNN
test_ops_fwd_gradients_xpu.py|test_forward_mode_AD_mv_xpu_float64 | All of the followings are oneDNN issues; RuntimeError: Double and complex datatype matmul is not supported in oneDNN
test_ops_fwd_gradients_xpu.py|test_inplace_forward_mode_AD_addbmm_xpu_float64 | All of the followings are oneDNN issues; RuntimeError: Double and complex datatype matmul is not supported in oneDNN
test_ops_fwd_gradients_xpu.py|test_inplace_forward_mode_AD_addmm_decomposed_xpu_float64 | All of the followings are oneDNN issues; RuntimeError: Double and complex datatype matmul is not supported in oneDNN
test_ops_fwd_gradients_xpu.py|test_inplace_forward_mode_AD_addmm_xpu_float64 | All of the followings are oneDNN issues; RuntimeError: Double and complex datatype matmul is not supported in oneDNN
test_ops_fwd_gradients_xpu.py|test_inplace_forward_mode_AD_addmv_xpu_float64 | All of the followings are oneDNN issues; RuntimeError: Double and complex datatype matmul is not supported in oneDNN
test_ops_fwd_gradients_xpu.py|test_inplace_forward_mode_AD_baddbmm_xpu_float64 | All of the followings are oneDNN issues; RuntimeError: Double and complex datatype matmul is not supported in oneDNN
test_ops_fwd_gradients_xpu.py|test_fn_fwgrad_bwgrad_nn_functional_conv_transpose2d_xpu_float64 | All of the followings are oneDNN issues; RuntimeError: Double and complex datatype matmul is not supported in oneDNN
test_ops_fwd_gradients_xpu.py|test_fn_fwgrad_bwgrad_nn_functional_conv_transpose3d_xpu_float64 | All of the followings are oneDNN issues; RuntimeError: Double and complex datatype matmul is not supported in oneDNN
test_ops_fwd_gradients_xpu.py|test_forward_mode_AD_nn_functional_conv_transpose2d_xpu_float64 | All of the followings are oneDNN issues; RuntimeError: Double and complex datatype matmul is not supported in oneDNN
test_ops_fwd_gradients_xpu.py|test_forward_mode_AD_nn_functional_conv_transpose3d_xpu_float64 | All of the followings are oneDNN issues; RuntimeError: Double and complex datatype matmul is not supported in oneDNN
quantization/core/test_quantized_op_xpu.py|test_qgelu_xpu | AssertionError: Torch not compiled with CUDA enabled
quantization/core/test_quantized_op_xpu.py|test_qrelu_xpu | AssertionError: Torch not compiled with CUDA enabled
quantization/core/test_quantized_op_xpu.py|test_qsoftmax_qnnpack_xpu | AttributeError: 'TestQuantizedOpsXPU' object has no attribute 'test_qsoftmax'
quantization/core/test_quantized_tensor_xpu.py|test_compare_per_channel_device_numerics_xpu | Summary: Quantized OPs are not supported for XPU; NotImplementedError: Could not run 'aten::dequantize.self' with arguments from the 'QuantizedXPU' backend
quantization/core/test_quantized_tensor_xpu.py|test_compare_per_tensor_device_numerics_xpu | NotImplementedError: Could not run 'aten::dequantize.self' with arguments from the 'QuantizedXPU' backend.
quantization/core/test_quantized_tensor_xpu.py|test_cuda_quantization_does_not_pin_memory_xpu | NotImplementedError: Could not run 'aten::empty_quantized' with arguments from the 'QuantizedXPU' backend.
quantization/core/test_quantized_tensor_xpu.py|test_per_channel_qtensor_creation_cuda_xpu | NotImplementedError: Could not run 'aten::_empty_per_channel_affine_quantized' with arguments from the 'QuantizedXPU' backend.
quantization/core/test_quantized_tensor_xpu.py|test_per_channel_to_device_xpu | NotImplementedError: Could not run 'aten::empty_quantized' with arguments from the 'QuantizedXPU' backend.
quantization/core/test_quantized_tensor_xpu.py|test_per_tensor_to_device_xpu | NotImplementedError: Could not run 'aten::empty_quantized' with arguments from the 'QuantizedXPU' backend.
quantization/core/test_quantized_tensor_xpu.py|test_qtensor_cuda_xpu | NotImplementedError: Could not run 'aten::q_scale' with arguments from the 'QuantizedXPU' backend.
quantization/core/test_quantized_tensor_xpu.py|test_qtensor_index_put_cuda_xpu | NotImplementedError: Could not run 'aten::_index_put_impl_' with arguments from the 'QuantizedXPU' backend.
quantization/core/test_quantized_tensor_xpu.py|test_qtensor_index_select_cuda_xpu | NotImplementedError: Could not run 'aten::index_select' with arguments from the 'QuantizedXPU' backend.
quantization/core/test_quantized_tensor_xpu.py|test_qtensor_masked_fill_cuda_xpu | NotImplementedError: Could not run 'aten::_empty_affine_quantized' with arguments from the 'QuantizedXPU' backend.
nn/test_packed_sequence_xpu.py|test_to and not test_to_memory and not test_total | test case porting issue
test_ops_gradients_xpu.py|test_fn_grad___rmatmul___xpu_float64 | All are oneDNN issues; ## Error #0 in TestBwdGradientsXPU , totally 271 , RuntimeError: Double and complex datatype matmul is not supported in oneDNN
test_ops_gradients_xpu.py|test_fn_grad_addbmm_xpu_float64 | All are oneDNN issues; ## Error #0 in TestBwdGradientsXPU , totally 271 , RuntimeError: Double and complex datatype matmul is not supported in oneDNN
test_ops_gradients_xpu.py|test_fn_grad_addmm_xpu_float64 | All are oneDNN issues; ## Error #0 in TestBwdGradientsXPU , totally 271 , RuntimeError: Double and complex datatype matmul is not supported in oneDNN
test_ops_gradients_xpu.py|test_fn_grad_addmv_xpu_float64 | All are oneDNN issues; ## Error #0 in TestBwdGradientsXPU , totally 271 , RuntimeError: Double and complex datatype matmul is not supported in oneDNN
test_ops_gradients_xpu.py|test_fn_grad_baddbmm_xpu_float64 | All are oneDNN issues; ## Error #0 in TestBwdGradientsXPU , totally 271 , RuntimeError: Double and complex datatype matmul is not supported in oneDNN
test_ops_gradients_xpu.py|test_fn_grad_cdist_xpu_float64 | All are oneDNN issues; ## Error #0 in TestBwdGradientsXPU , totally 271 , RuntimeError: Double and complex datatype matmul is not supported in oneDNN
test_ops_gradients_xpu.py|test_fn_grad_matmul_xpu_float64 | All are oneDNN issues; ## Error #0 in TestBwdGradientsXPU , totally 271 , RuntimeError: Double and complex datatype matmul is not supported in oneDNN
test_ops_gradients_xpu.py|test_fn_grad_mv_xpu_float64 | All are oneDNN issues; ## Error #0 in TestBwdGradientsXPU , totally 271 , RuntimeError: Double and complex datatype matmul is not supported in oneDNN
test_ops_gradients_xpu.py|test_fn_grad_nn_functional_multi_head_attention_forward_xpu_float64 | All are oneDNN issues; ## Error #0 in TestBwdGradientsXPU , totally 271 , RuntimeError: Double and complex datatype matmul is not supported in oneDNN
test_ops_gradients_xpu.py|test_fn_gradgrad___rmatmul___xpu_float64 | All are oneDNN issues; ## Error #0 in TestBwdGradientsXPU , totally 271 , RuntimeError: Double and complex datatype matmul is not supported in oneDNN
test_ops_gradients_xpu.py|test_fn_gradgrad_addmv_xpu_float64 | All are oneDNN issues; ## Error #0 in TestBwdGradientsXPU , totally 271 , RuntimeError: Double and complex datatype matmul is not supported in oneDNN
test_ops_gradients_xpu.py|test_fn_gradgrad_addr_xpu_float64 | All are oneDNN issues; ## Error #0 in TestBwdGradientsXPU , totally 271 , RuntimeError: Double and complex datatype matmul is not supported in oneDNN
test_ops_gradients_xpu.py|test_fn_gradgrad_matmul_xpu_float64 | All are oneDNN issues; ## Error #0 in TestBwdGradientsXPU , totally 271 , RuntimeError: Double and complex datatype matmul is not supported in oneDNN
test_ops_gradients_xpu.py|test_fn_gradgrad_mv_xpu_float64 | All are oneDNN issues; ## Error #0 in TestBwdGradientsXPU , totally 271 , RuntimeError: Double and complex datatype matmul is not supported in oneDNN
test_ops_gradients_xpu.py|test_inplace_grad_addbmm_xpu_float64 | All are oneDNN issues; ## Error #0 in TestBwdGradientsXPU , totally 271 , RuntimeError: Double and complex datatype matmul is not supported in oneDNN
test_ops_gradients_xpu.py|test_inplace_grad_addmm_decomposed_xpu_float64 | All are oneDNN issues; ## Error #0 in TestBwdGradientsXPU , totally 271 , RuntimeError: Double and complex datatype matmul is not supported in oneDNN
test_ops_gradients_xpu.py|test_inplace_grad_addmm_xpu_float64 | All are oneDNN issues; ## Error #0 in TestBwdGradientsXPU , totally 271 , RuntimeError: Double and complex datatype matmul is not supported in oneDNN
test_ops_gradients_xpu.py|test_inplace_grad_addmv_xpu_float64 | All are oneDNN issues; ## Error #0 in TestBwdGradientsXPU , totally 271 , RuntimeError: Double and complex datatype matmul is not supported in oneDNN
test_ops_gradients_xpu.py|test_inplace_grad_baddbmm_xpu_float64 | All are oneDNN issues; ## Error #0 in TestBwdGradientsXPU , totally 271 , RuntimeError: Double and complex datatype matmul is not supported in oneDNN
test_ops_gradients_xpu.py|test_inplace_gradgrad_addmv_xpu_float64 | All are oneDNN issues; ## Error #0 in TestBwdGradientsXPU , totally 271 , RuntimeError: Double and complex datatype matmul is not supported in oneDNN
test_ops_gradients_xpu.py|test_inplace_gradgrad_addr_xpu_float64 | All are oneDNN issues; ## Error #0 in TestBwdGradientsXPU , totally 271 , RuntimeError: Double and complex datatype matmul is not supported in oneDNN
test_ops_gradients_xpu.py|test_fn_grad_nn_functional_conv_transpose2d_xpu_float64 | All are oneDNN issues; ## Error #0 in TestBwdGradientsXPU , totally 271 , RuntimeError: Double and complex datatype matmul is not supported in oneDNN
test_ops_gradients_xpu.py|test_fn_grad_nn_functional_conv_transpose3d_xpu_float64 | All are oneDNN issues; ## Error #0 in TestBwdGradientsXPU , totally 271 , RuntimeError: Double and complex datatype matmul is not supported in oneDNN
test_ops_gradients_xpu.py|test_fn_gradgrad_nn_functional_conv_transpose2d_xpu_float64 | All are oneDNN issues; ## Error #0 in TestBwdGradientsXPU , totally 271 , RuntimeError: Double and complex datatype matmul is not supported in oneDNN
test_ops_gradients_xpu.py|test_fn_gradgrad_nn_functional_conv_transpose3d_xpu_float64 | All are oneDNN issues; ## Error #0 in TestBwdGradientsXPU , totally 271 , RuntimeError: Double and complex datatype matmul is not supported in oneDNN
test_ops_gradients_xpu.py|test_fn_gradgrad_index_reduce_mean_xpu_float64 | All are oneDNN issues; ## Error #0 in TestBwdGradientsXPU , totally 271 , RuntimeError: Double and complex datatype matmul is not supported in oneDNN
test_ops_gradients_xpu.py|test_fn_gradgrad_index_reduce_prod_xpu_float64 | All are oneDNN issues; ## Error #0 in TestBwdGradientsXPU , totally 271 , RuntimeError: Double and complex datatype matmul is not supported in oneDNN
test_ops_gradients_xpu.py|test_inplace_gradgrad_index_reduce_mean_xpu_float64 | All are oneDNN issues; ## Error #0 in TestBwdGradientsXPU , totally 271 , RuntimeError: Double and complex datatype matmul is not supported in oneDNN
test_ops_gradients_xpu.py|test_inplace_gradgrad_index_reduce_prod_xpu_float64 | All are oneDNN issues; ## Error #0 in TestBwdGradientsXPU , totally 271 , RuntimeError: Double and complex datatype matmul is not supported in oneDNN
test_torch_xpu.py|test_grad_scaling_state_dict_xpu | 'torch.xpu' has no attribute ...; ## Error #1 in TestTorchDeviceTypeXPU , totally 2 , AttributeError: module 'torch.xpu' has no attribute 'FloatTensor'
test_torch_xpu.py|test_storage_setitem_xpu_uint8 | ## Error #2 in TestTorchDeviceTypeXPU , totally 1 , AttributeError: 'torch.storage.TypedStorage' object has no attribute 'is_xpu'; ## Error #3 in TestTorchDeviceTypeXPU , totally 3 , AttributeError: module 'torch.xpu' has no attribute 'ByteStorage'
test_torch_xpu.py|test_tensor_storage_type_xpu_uint8 | ## Module 'torch.xpu' has no attribute 'ByteStorage'
test_torch_xpu.py|test_storage_setitem_xpu_float32 | ## Error #4 in TestTorchDeviceTypeXPU , totally 4 , AttributeError: module 'torch.xpu' has no attribute 'FloatStorage'
test_torch_xpu.py|test_tensor_storage_type_xpu_float32 | ## Error #4 in TestTorchDeviceTypeXPU , totally 4 , AttributeError: module 'torch.xpu' has no attribute 'FloatStorage'
test_torch_xpu.py|test_broadcast_fn_map2_xpu | ## Error #7 in TestTorchDeviceTypeXPU , totally 1 , TypeError: map2_ is only implemented on CPU tensors
test_torch_xpu.py|test_broadcast_fn_map_xpu | ## Error #8 in TestTorchDeviceTypeXPU , totally 1 , TypeError: map_ is only implemented on CPU tensors
test_torch_xpu.py|test_grad_scaler_pass_itself_xpu | ## Error #12 in TestTorchDeviceTypeXPU , totally 2 , AttributeError: module 'torch.xpu' has no attribute 'amp'
test_torch_xpu.py|test_pickle_gradscaler_xpu | ## Error #12 in TestTorchDeviceTypeXPU , totally 2 , AttributeError: module 'torch.xpu' has no attribute 'amp'
test_torch_xpu.py|test_index_put_non_accumulate_deterministic_xpu | ## Error #15 in TestTorchDeviceTypeXPU , totally 2 , AssertionError: Tensor-likes are not close!
test_torch_xpu.py|test_sync_warning_xpu | ## Error #17 in TestTorchDeviceTypeXPU , totally 2 , AssertionError: False is not true
test_torch_xpu.py|test_module_share_memory_xpu | ## Error #19 in TestTorchDeviceTypeXPU , totally 1 , RuntimeError: _share_fd_: only available on CPU
test_torch_xpu.py|test_storage_setitem_xpu_bool | 'torch.xpu' has no attribute ...; ## Error #30 in TestTorchDeviceTypeXPU , totally 2 , AttributeError: module 'torch.xpu' has no attribute 'BoolStorage'
test_torch_xpu.py|test_tensor_storage_type_xpu_bool | 'torch.xpu' has no attribute ...; ## Error #30 in TestTorchDeviceTypeXPU , totally 2 , AttributeError: module 'torch.xpu' has no attribute 'BoolStorage'
test_torch_xpu.py|test_storage_setitem_xpu_float64 | ## Error #33 in TestTorchDeviceTypeXPU , totally 2 , AttributeError: module 'torch.xpu' has no attribute 'DoubleStorage'
test_torch_xpu.py|test_tensor_storage_type_xpu_float64 | ## Error #33 in TestTorchDeviceTypeXPU , totally 2 , AttributeError: module 'torch.xpu' has no attribute 'DoubleStorage'
test_torch_xpu.py|test_storage_setitem_xpu_int16 | ## Error #34 in TestTorchDeviceTypeXPU , totally 2 , AttributeError: module 'torch.xpu' has no attribute 'ShortStorage'
test_torch_xpu.py|test_tensor_storage_type_xpu_int16 | ## Error #34 in TestTorchDeviceTypeXPU , totally 2 , AttributeError: module 'torch.xpu' has no attribute 'ShortStorage'
test_torch_xpu.py|test_storage_setitem_xpu_int32 | ## Error #35 in TestTorchDeviceTypeXPU , totally 2 , AttributeError: module 'torch.xpu' has no attribute 'IntStorage'
test_torch_xpu.py|test_tensor_storage_type_xpu_int32 | ## Error #35 in TestTorchDeviceTypeXPU , totally 2 , AttributeError: module 'torch.xpu' has no attribute 'IntStorage'
test_torch_xpu.py|test_storage_setitem_xpu_int64 | ## Error #36 in TestTorchDeviceTypeXPU , totally 2 , AttributeError: module 'torch.xpu' has no attribute 'LongStorage'
test_torch_xpu.py|test_tensor_storage_type_xpu_int64 | ## Error #36 in TestTorchDeviceTypeXPU , totally 2 , AttributeError: module 'torch.xpu' has no attribute 'LongStorage'
test_torch_xpu.py|test_storage_setitem_xpu_int8 | ## Error #37 in TestTorchDeviceTypeXPU , totally 2 , AttributeError: module 'torch.xpu' has no attribute 'CharStorage'
test_torch_xpu.py|test_tensor_storage_type_xpu_int8 | ## Error #37 in TestTorchDeviceTypeXPU , totally 2 , AttributeError: module 'torch.xpu' has no attribute 'CharStorage'
test_torch_xpu.py|test_tensor_storage_type_xpu_bfloat16 | ## Error #38 in TestTorchDeviceTypeXPU , totally 1 , AttributeError: module 'torch.xpu' has no attribute 'BFloat16Storage'
test_torch_xpu.py|test_tensor_storage_type_xpu_float16 | ## Error #39 in TestTorchDeviceTypeXPU , totally 1 , AttributeError: module 'torch.xpu' has no attribute 'HalfStorage'
test_torch_xpu.py|test_print | issue 302 , 8
test_torch_xpu.py|test_storage_error | issue 302, 6
test_torch_xpu.py|test_storage_error_no_attribute | issue 302 , 8
test_torch_xpu.py|test_typed_storage_deprecation_warning | issue 302, 6
test_torch_xpu.py|test_typed_storage_internal_no_warning | issue 302, 6
test_torch_xpu.py|test_cuda_vitals_gpu_only_xpu | issue 302, 11
test_torch_xpu.py|test_swap_basic | torch.utils.swap_tensors AssertionError: RuntimeError not raised
test_torch_xpu.py|test_index_copy_deterministic | internally uses index_put deterministic implementation; dependent on "test_index_put_non_accumulate_deterministic"
test_foreach_xpu.py|use_cuda_graph_True | RuntimeError: Tried to instantiate dummy base class CUDAGraph
test_foreach_xpu.py|test_parity__foreach_div_fastpath_inplace_xpu_complex128 | randomly fails
test_foreach_xpu.py|test_parity__foreach_div_fastpath_outplace_xpu_complex128 | randomly fails
test_foreach_xpu.py|test_parity__foreach_addcdiv_fastpath_inplace_xpu_complex128 | randomly fails
test_foreach_xpu.py|test_parity__foreach_addcdiv_fastpath_outplace_xpu_complex128 | randomly fails
nn/test_convolution_xpu.py|test_cudnn_convolution_relu_xpu_float16 | Summary: all of them are oneDNN related issues; XPU unsupport ops, skip.; https://github.com/intel/torch-xpu-ops/issues/348
nn/test_convolution_xpu.py|test_cudnn_convolution_relu_xpu_float32 | Summary: all of them are oneDNN related issues; XPU unsupport ops, skip.; https://github.com/intel/torch-xpu-ops/issues/348
nn/test_convolution_xpu.py|test_cudnn_convolution_add_relu_xpu_float16 | Summary: all of them are oneDNN related issues; XPU unsupport ops, skip.; https://github.com/intel/torch-xpu-ops/issues/348
nn/test_convolution_xpu.py|test_cudnn_convolution_add_relu_xpu_float32 | Summary: all of them are oneDNN related issues; XPU unsupport ops, skip.; https://github.com/intel/torch-xpu-ops/issues/348
nn/test_convolution_xpu.py|test_Conv2d_naive_groups_xpu_float16 | accuracy issue, TODO
nn/test_convolution_xpu.py|test_thnn_conv_strided_padded_dilated | issue: https://github.com/intel/torch-xpu-ops/issues/809
nn/test_module_hooks_xpu.py|test_register_state_dict_post_hook | TypeError: TestStateDictHooks.test_register_state_dict_post_hook() missing 1 required positional argument: 'private'; https://github.com/intel/torch-xpu-ops/issues/658
test_meta_xpu.py|_jiterator_ | https://github.com/intel/torch-xpu-ops/issues/774
test_meta_xpu.py|test_dispatch_meta_outplace_nn_functional_linear_xpu_int16 | RuntimeError: Short is not supported in oneDNN! Need oneDNN's support, suggest to keep skip.
test_meta_xpu.py|test_dispatch_symbolic_meta_outplace_nn_functional_linear_xpu_int16 | RuntimeError: Short is not supported in oneDNN! Need oneDNN's support, suggest to keep skip.
test_meta_xpu.py|test_meta_outplace_nn_functional_linear_xpu_int16 | RuntimeError: Short is not supported in oneDNN! Need oneDNN's support, suggest to keep skip.
test_meta_xpu.py|test_dispatch_meta_outplace_nn_functional_linear_xpu_int64 | RuntimeError: Long is not supported in oneDNN! Need oneDNN's support, suggest to keep skip.
test_meta_xpu.py|test_dispatch_symbolic_meta_outplace_nn_functional_linear_xpu_int64 | RuntimeError: Long is not supported in oneDNN! Need oneDNN's support, suggest to keep skip.
test_meta_xpu.py|test_meta_outplace_nn_functional_linear_xpu_int64 | RuntimeError: Long is not supported in oneDNN! Need oneDNN's support, suggest to keep skip.
test_meta_xpu.py|test_dispatch_meta_inplace_addbmm_xpu_int16 | RuntimeError: Short is not supported in oneDNN!
test_meta_xpu.py|test_dispatch_meta_inplace_addmm_decomposed_xpu_int16 | RuntimeError: Short is not supported in oneDNN!
test_meta_xpu.py|test_dispatch_meta_inplace_addmm_xpu_int16 | RuntimeError: Short is not supported in oneDNN!
test_meta_xpu.py|test_dispatch_meta_inplace_addmv_xpu_int16 | RuntimeError: Short is not supported in oneDNN!
test_meta_xpu.py|test_dispatch_meta_inplace_baddbmm_xpu_int16 | RuntimeError: Short is not supported in oneDNN!
test_meta_xpu.py|test_dispatch_meta_outplace___rmatmul___xpu_int16 | RuntimeError: Short is not supported in oneDNN!
test_meta_xpu.py|test_dispatch_meta_outplace_addbmm_xpu_int16 | RuntimeError: Short is not supported in oneDNN!
test_meta_xpu.py|test_dispatch_meta_outplace_addmm_decomposed_xpu_int16 | RuntimeError: Short is not supported in oneDNN!
test_meta_xpu.py|test_dispatch_meta_outplace_addmm_xpu_int16 | RuntimeError: Short is not supported in oneDNN!
test_meta_xpu.py|test_dispatch_meta_outplace_addmv_xpu_int16 | RuntimeError: Short is not supported in oneDNN!
test_meta_xpu.py|test_dispatch_meta_outplace_baddbmm_xpu_int16 | RuntimeError: Short is not supported in oneDNN!
test_meta_xpu.py|test_dispatch_meta_outplace_bmm_xpu_int16 | RuntimeError: Short is not supported in oneDNN!
test_meta_xpu.py|test_dispatch_meta_outplace_einsum_xpu_int16 | RuntimeError: Short is not supported in oneDNN!
test_meta_xpu.py|test_dispatch_meta_outplace_linalg_multi_dot_xpu_int16 | RuntimeError: Short is not supported in oneDNN!
test_meta_xpu.py|test_dispatch_meta_outplace_matmul_xpu_int16 | RuntimeError: Short is not supported in oneDNN!
test_meta_xpu.py|test_dispatch_meta_outplace_mm_xpu_int16 | RuntimeError: Short is not supported in oneDNN!
test_meta_xpu.py|test_dispatch_meta_outplace_mv_xpu_int16 | RuntimeError: Short is not supported in oneDNN!
test_meta_xpu.py|test_dispatch_meta_outplace_nn_functional_bilinear_xpu_int16 | RuntimeError: Short is not supported in oneDNN!
test_meta_xpu.py|test_dispatch_meta_outplace_tensordot_xpu_int16 | RuntimeError: Short is not supported in oneDNN!
test_meta_xpu.py|test_dispatch_symbolic_meta_inplace_addbmm_xpu_int16 | RuntimeError: Short is not supported in oneDNN!
test_meta_xpu.py|test_dispatch_symbolic_meta_inplace_addmm_decomposed_xpu_int16 | RuntimeError: Short is not supported in oneDNN!
test_meta_xpu.py|test_dispatch_symbolic_meta_inplace_addmm_xpu_int16 | RuntimeError: Short is not supported in oneDNN!
test_meta_xpu.py|test_dispatch_symbolic_meta_inplace_addmv_xpu_int16 | RuntimeError: Short is not supported in oneDNN!
test_meta_xpu.py|test_dispatch_symbolic_meta_inplace_baddbmm_xpu_int16 | RuntimeError: Short is not supported in oneDNN!
test_meta_xpu.py|test_dispatch_symbolic_meta_outplace___rmatmul___xpu_int16 | RuntimeError: Short is not supported in oneDNN!
test_meta_xpu.py|test_dispatch_symbolic_meta_outplace_addbmm_xpu_int16 | RuntimeError: Short is not supported in oneDNN!
test_meta_xpu.py|test_dispatch_symbolic_meta_outplace_addmm_decomposed_xpu_int16 | RuntimeError: Short is not supported in oneDNN!
test_meta_xpu.py|test_dispatch_symbolic_meta_outplace_addmm_xpu_int16 | RuntimeError: Short is not supported in oneDNN!
test_meta_xpu.py|test_dispatch_symbolic_meta_outplace_addmv_xpu_int16 | RuntimeError: Short is not supported in oneDNN!
test_meta_xpu.py|test_dispatch_symbolic_meta_outplace_baddbmm_xpu_int16 | RuntimeError: Short is not supported in oneDNN!
test_meta_xpu.py|test_dispatch_symbolic_meta_outplace_bmm_xpu_int16 | RuntimeError: Short is not supported in oneDNN!
test_meta_xpu.py|test_dispatch_symbolic_meta_outplace_einsum_xpu_int16 | RuntimeError: Short is not supported in oneDNN!
test_meta_xpu.py|test_dispatch_symbolic_meta_outplace_linalg_multi_dot_xpu_int16 | RuntimeError: Short is not supported in oneDNN!
test_meta_xpu.py|test_dispatch_symbolic_meta_outplace_matmul_xpu_int16 | RuntimeError: Short is not supported in oneDNN!
test_meta_xpu.py|test_dispatch_symbolic_meta_outplace_mm_xpu_int16 | RuntimeError: Short is not supported in oneDNN!
test_meta_xpu.py|test_dispatch_symbolic_meta_outplace_mv_xpu_int16 | RuntimeError: Short is not supported in oneDNN!
test_meta_xpu.py|test_dispatch_symbolic_meta_outplace_nn_functional_bilinear_xpu_int16 | RuntimeError: Short is not supported in oneDNN!
test_meta_xpu.py|test_dispatch_symbolic_meta_outplace_tensordot_xpu_int16 | RuntimeError: Short is not supported in oneDNN!
test_meta_xpu.py|test_meta_inplace_addbmm_xpu_int16 | RuntimeError: Short is not supported in oneDNN!
test_meta_xpu.py|test_meta_inplace_addmm_decomposed_xpu_int16 | RuntimeError: Short is not supported in oneDNN!
test_meta_xpu.py|test_meta_inplace_addmm_xpu_int16 | RuntimeError: Short is not supported in oneDNN!
test_meta_xpu.py|test_meta_inplace_addmv_xpu_int16 | RuntimeError: Short is not supported in oneDNN!
test_meta_xpu.py|test_meta_inplace_baddbmm_xpu_int16 | RuntimeError: Short is not supported in oneDNN!
test_meta_xpu.py|test_meta_outplace___rmatmul___xpu_int16 | RuntimeError: Short is not supported in oneDNN!
test_meta_xpu.py|test_meta_outplace_addbmm_xpu_int16 | RuntimeError: Short is not supported in oneDNN!
test_meta_xpu.py|test_meta_outplace_addmm_decomposed_xpu_int16 | RuntimeError: Short is not supported in oneDNN!
test_meta_xpu.py|test_meta_outplace_addmm_xpu_int16 | RuntimeError: Short is not supported in oneDNN!
test_meta_xpu.py|test_meta_outplace_addmv_xpu_int16 | RuntimeError: Short is not supported in oneDNN!
test_meta_xpu.py|test_meta_outplace_baddbmm_xpu_int16 | RuntimeError: Short is not supported in oneDNN!
test_meta_xpu.py|test_meta_outplace_bmm_xpu_int16 | RuntimeError: Short is not supported in oneDNN!
test_meta_xpu.py|test_meta_outplace_einsum_xpu_int16 | RuntimeError: Short is not supported in oneDNN!
test_meta_xpu.py|test_meta_outplace_linalg_multi_dot_xpu_int16 | RuntimeError: Short is not supported in oneDNN!
test_meta_xpu.py|test_meta_outplace_matmul_xpu_int16 | RuntimeError: Short is not supported in oneDNN!
test_meta_xpu.py|test_meta_outplace_mm_xpu_int16 | RuntimeError: Short is not supported in oneDNN!
test_meta_xpu.py|test_meta_outplace_mv_xpu_int16 | RuntimeError: Short is not supported in oneDNN!
test_meta_xpu.py|test_meta_outplace_nn_functional_bilinear_xpu_int16 | RuntimeError: Short is not supported in oneDNN!
test_meta_xpu.py|test_meta_outplace_tensordot_xpu_int16 | RuntimeError: Short is not supported in oneDNN!
test_meta_xpu.py|test_dispatch_meta_inplace_addbmm_xpu_int32 | RuntimeError: could not create a primitive descriptor for a matmul primitive
test_meta_xpu.py|test_dispatch_meta_inplace_addmm_decomposed_xpu_int32 | RuntimeError: could not create a primitive descriptor for a matmul primitive
test_meta_xpu.py|test_dispatch_meta_inplace_addmm_xpu_int32 | RuntimeError: could not create a primitive descriptor for a matmul primitive
test_meta_xpu.py|test_dispatch_meta_inplace_addmv_xpu_int32 | RuntimeError: could not create a primitive descriptor for a matmul primitive
test_meta_xpu.py|test_dispatch_meta_inplace_baddbmm_xpu_int32 | RuntimeError: could not create a primitive descriptor for a matmul primitive
test_meta_xpu.py|test_dispatch_meta_outplace___rmatmul___xpu_int32 | RuntimeError: could not create a primitive descriptor for a matmul primitive
test_meta_xpu.py|test_dispatch_meta_outplace_addbmm_xpu_int32 | RuntimeError: could not create a primitive descriptor for a matmul primitive
test_meta_xpu.py|test_dispatch_meta_outplace_addmm_decomposed_xpu_int32 | RuntimeError: could not create a primitive descriptor for a matmul primitive
test_meta_xpu.py|test_dispatch_meta_outplace_addmm_xpu_int32 | RuntimeError: could not create a primitive descriptor for a matmul primitive
test_meta_xpu.py|test_dispatch_meta_outplace_addmv_xpu_int32 | RuntimeError: could not create a primitive descriptor for a matmul primitive
test_meta_xpu.py|test_dispatch_meta_outplace_baddbmm_xpu_int32 | RuntimeError: could not create a primitive descriptor for a matmul primitive
test_meta_xpu.py|test_dispatch_meta_outplace_bmm_xpu_int32 | RuntimeError: could not create a primitive descriptor for a matmul primitive
test_meta_xpu.py|test_dispatch_meta_outplace_einsum_xpu_int32 | RuntimeError: could not create a primitive descriptor for a matmul primitive
test_meta_xpu.py|test_dispatch_meta_outplace_linalg_multi_dot_xpu_int32 | RuntimeError: could not create a primitive descriptor for a matmul primitive
test_meta_xpu.py|test_dispatch_meta_outplace_matmul_xpu_int32 | RuntimeError: could not create a primitive descriptor for a matmul primitive
test_meta_xpu.py|test_dispatch_meta_outplace_mm_xpu_int32 | RuntimeError: could not create a primitive descriptor for a matmul primitive
test_meta_xpu.py|test_dispatch_meta_outplace_mv_xpu_int32 | RuntimeError: could not create a primitive descriptor for a matmul primitive
test_meta_xpu.py|test_dispatch_meta_outplace_nn_functional_bilinear_xpu_int32 | RuntimeError: could not create a primitive descriptor for a matmul primitive
test_meta_xpu.py|test_dispatch_meta_outplace_nn_functional_linear_xpu_int32 | RuntimeError: could not create a primitive descriptor for a matmul primitive
test_meta_xpu.py|test_dispatch_meta_outplace_tensordot_xpu_int32 | RuntimeError: could not create a primitive descriptor for a matmul primitive
test_meta_xpu.py|test_dispatch_symbolic_meta_inplace_addbmm_xpu_int32 | RuntimeError: could not create a primitive descriptor for a matmul primitive
test_meta_xpu.py|test_dispatch_symbolic_meta_inplace_addmm_decomposed_xpu_int32 | RuntimeError: could not create a primitive descriptor for a matmul primitive
test_meta_xpu.py|test_dispatch_symbolic_meta_inplace_addmm_xpu_int32 | RuntimeError: could not create a primitive descriptor for a matmul primitive
test_meta_xpu.py|test_dispatch_symbolic_meta_inplace_addmv_xpu_int32 | RuntimeError: could not create a primitive descriptor for a matmul primitive
test_meta_xpu.py|test_dispatch_symbolic_meta_inplace_baddbmm_xpu_int32 | RuntimeError: could not create a primitive descriptor for a matmul primitive
test_meta_xpu.py|test_dispatch_symbolic_meta_outplace___rmatmul___xpu_int32 | RuntimeError: could not create a primitive descriptor for a matmul primitive
test_meta_xpu.py|test_dispatch_symbolic_meta_outplace_addbmm_xpu_int32 | RuntimeError: could not create a primitive descriptor for a matmul primitive
test_meta_xpu.py|test_dispatch_symbolic_meta_outplace_addmm_decomposed_xpu_int32 | RuntimeError: could not create a primitive descriptor for a matmul primitive
test_meta_xpu.py|test_dispatch_symbolic_meta_outplace_addmm_xpu_int32 | RuntimeError: could not create a primitive descriptor for a matmul primitive
test_meta_xpu.py|test_dispatch_symbolic_meta_outplace_addmv_xpu_int32 | RuntimeError: could not create a primitive descriptor for a matmul primitive
test_meta_xpu.py|test_dispatch_symbolic_meta_outplace_baddbmm_xpu_int32 | RuntimeError: could not create a primitive descriptor for a matmul primitive
test_meta_xpu.py|test_dispatch_symbolic_meta_outplace_bmm_xpu_int32 | RuntimeError: could not create a primitive descriptor for a matmul primitive
test_meta_xpu.py|test_dispatch_symbolic_meta_outplace_einsum_xpu_int32 | RuntimeError: could not create a primitive descriptor for a matmul primitive
test_meta_xpu.py|test_dispatch_symbolic_meta_outplace_linalg_multi_dot_xpu_int32 | RuntimeError: could not create a primitive descriptor for a matmul primitive
test_meta_xpu.py|test_dispatch_symbolic_meta_outplace_matmul_xpu_int32 | RuntimeError: could not create a primitive descriptor for a matmul primitive
test_meta_xpu.py|test_dispatch_symbolic_meta_outplace_mm_xpu_int32 | RuntimeError: could not create a primitive descriptor for a matmul primitive
test_meta_xpu.py|test_dispatch_symbolic_meta_outplace_mv_xpu_int32 | RuntimeError: could not create a primitive descriptor for a matmul primitive
test_meta_xpu.py|test_dispatch_symbolic_meta_outplace_nn_functional_bilinear_xpu_int32 | RuntimeError: could not create a primitive descriptor for a matmul primitive
test_meta_xpu.py|test_dispatch_symbolic_meta_outplace_nn_functional_linear_xpu_int32 | RuntimeError: could not create a primitive descriptor for a matmul primitive
test_meta_xpu.py|test_dispatch_symbolic_meta_outplace_tensordot_xpu_int32 | RuntimeError: could not create a primitive descriptor for a matmul primitive
test_meta_xpu.py|test_meta_inplace_addbmm_xpu_int32 | RuntimeError: could not create a primitive descriptor for a matmul primitive
test_meta_xpu.py|test_meta_inplace_addmm_decomposed_xpu_int32 | RuntimeError: could not create a primitive descriptor for a matmul primitive
test_meta_xpu.py|test_meta_inplace_addmm_xpu_int32 | RuntimeError: could not create a primitive descriptor for a matmul primitive
test_meta_xpu.py|test_meta_inplace_addmv_xpu_int32 | RuntimeError: could not create a primitive descriptor for a matmul primitive
test_meta_xpu.py|test_meta_inplace_baddbmm_xpu_int32 | RuntimeError: could not create a primitive descriptor for a matmul primitive
test_meta_xpu.py|test_meta_outplace___rmatmul___xpu_int32 | RuntimeError: could not create a primitive descriptor for a matmul primitive
test_meta_xpu.py|test_meta_outplace_addbmm_xpu_int32 | RuntimeError: could not create a primitive descriptor for a matmul primitive
test_meta_xpu.py|test_meta_outplace_addmm_decomposed_xpu_int32 | RuntimeError: could not create a primitive descriptor for a matmul primitive
test_meta_xpu.py|test_meta_outplace_addmm_xpu_int32 | RuntimeError: could not create a primitive descriptor for a matmul primitive
test_meta_xpu.py|test_meta_outplace_addmv_xpu_int32 | RuntimeError: could not create a primitive descriptor for a matmul primitive
test_meta_xpu.py|test_meta_outplace_baddbmm_xpu_int32 | RuntimeError: could not create a primitive descriptor for a matmul primitive
test_meta_xpu.py|test_meta_outplace_bmm_xpu_int32 | RuntimeError: could not create a primitive descriptor for a matmul primitive
test_meta_xpu.py|test_meta_outplace_einsum_xpu_int32 | RuntimeError: could not create a primitive descriptor for a matmul primitive
test_meta_xpu.py|test_meta_outplace_linalg_multi_dot_xpu_int32 | RuntimeError: could not create a primitive descriptor for a matmul primitive
test_meta_xpu.py|test_meta_outplace_matmul_xpu_int32 | RuntimeError: could not create a primitive descriptor for a matmul primitive
test_meta_xpu.py|test_meta_outplace_mm_xpu_int32 | RuntimeError: could not create a primitive descriptor for a matmul primitive
test_meta_xpu.py|test_meta_outplace_mv_xpu_int32 | RuntimeError: could not create a primitive descriptor for a matmul primitive
test_meta_xpu.py|test_meta_outplace_nn_functional_bilinear_xpu_int32 | RuntimeError: could not create a primitive descriptor for a matmul primitive
test_meta_xpu.py|test_meta_outplace_nn_functional_linear_xpu_int32 | RuntimeError: could not create a primitive descriptor for a matmul primitive
test_meta_xpu.py|test_meta_outplace_tensordot_xpu_int32 | RuntimeError: could not create a primitive descriptor for a matmul primitive
test_meta_xpu.py|test_dispatch_meta_inplace_addbmm_xpu_int64 | RuntimeError: Long is not supported in oneDNN!
test_meta_xpu.py|test_dispatch_meta_inplace_addmm_decomposed_xpu_int64 | RuntimeError: Long is not supported in oneDNN!
test_meta_xpu.py|test_dispatch_meta_inplace_addmm_xpu_int64 | RuntimeError: Long is not supported in oneDNN!
test_meta_xpu.py|test_dispatch_meta_inplace_addmv_xpu_int64 | RuntimeError: Long is not supported in oneDNN!
test_meta_xpu.py|test_dispatch_meta_inplace_baddbmm_xpu_int64 | RuntimeError: Long is not supported in oneDNN!
test_meta_xpu.py|test_dispatch_meta_outplace___rmatmul___xpu_int64 | RuntimeError: Long is not supported in oneDNN!
test_meta_xpu.py|test_dispatch_meta_outplace_addbmm_xpu_int64 | RuntimeError: Long is not supported in oneDNN!
test_meta_xpu.py|test_dispatch_meta_outplace_addmm_decomposed_xpu_int64 | RuntimeError: Long is not supported in oneDNN!
test_meta_xpu.py|test_dispatch_meta_outplace_addmm_xpu_int64 | RuntimeError: Long is not supported in oneDNN!
test_meta_xpu.py|test_dispatch_meta_outplace_addmv_xpu_int64 | RuntimeError: Long is not supported in oneDNN!
test_meta_xpu.py|test_dispatch_meta_outplace_baddbmm_xpu_int64 | RuntimeError: Long is not supported in oneDNN!
test_meta_xpu.py|test_dispatch_meta_outplace_bmm_xpu_int64 | RuntimeError: Long is not supported in oneDNN!
test_meta_xpu.py|test_dispatch_meta_outplace_einsum_xpu_int64 | RuntimeError: Long is not supported in oneDNN!
test_meta_xpu.py|test_dispatch_meta_outplace_linalg_multi_dot_xpu_int64 | RuntimeError: Long is not supported in oneDNN!
test_meta_xpu.py|test_dispatch_meta_outplace_matmul_xpu_int64 | RuntimeError: Long is not supported in oneDNN!
test_meta_xpu.py|test_dispatch_meta_outplace_mm_xpu_int64 | RuntimeError: Long is not supported in oneDNN!
test_meta_xpu.py|test_dispatch_meta_outplace_mv_xpu_int64 | RuntimeError: Long is not supported in oneDNN!
test_meta_xpu.py|test_dispatch_meta_outplace_nn_functional_bilinear_xpu_int64 | RuntimeError: Long is not supported in oneDNN!
test_meta_xpu.py|test_dispatch_meta_outplace_nn_functional_conv1d_xpu_int64 | RuntimeError: Long is not supported in oneDNN!
test_meta_xpu.py|test_dispatch_meta_outplace_nn_functional_conv2d_xpu_int64 | RuntimeError: Long is not supported in oneDNN!
test_meta_xpu.py|test_dispatch_meta_outplace_nn_functional_conv3d_xpu_int64 | RuntimeError: Long is not supported in oneDNN!
test_meta_xpu.py|test_dispatch_meta_outplace_nn_functional_conv_transpose1d_xpu_int64 | RuntimeError: Long is not supported in oneDNN!
test_meta_xpu.py|test_dispatch_meta_outplace_nn_functional_conv_transpose2d_xpu_int64 | RuntimeError: Long is not supported in oneDNN!
test_meta_xpu.py|test_dispatch_meta_outplace_nn_functional_conv_transpose3d_xpu_int64 | RuntimeError: Long is not supported in oneDNN!
test_meta_xpu.py|test_dispatch_meta_outplace_tensordot_xpu_int64 | RuntimeError: Long is not supported in oneDNN!
test_meta_xpu.py|test_dispatch_symbolic_meta_inplace_addbmm_xpu_int64 | RuntimeError: Long is not supported in oneDNN!
test_meta_xpu.py|test_dispatch_symbolic_meta_inplace_addmm_decomposed_xpu_int64 | RuntimeError: Long is not supported in oneDNN!
test_meta_xpu.py|test_dispatch_symbolic_meta_inplace_addmm_xpu_int64 | RuntimeError: Long is not supported in oneDNN!
test_meta_xpu.py|test_dispatch_symbolic_meta_inplace_addmv_xpu_int64 | RuntimeError: Long is not supported in oneDNN!
test_meta_xpu.py|test_dispatch_symbolic_meta_inplace_baddbmm_xpu_int64 | RuntimeError: Long is not supported in oneDNN!
test_meta_xpu.py|test_dispatch_symbolic_meta_outplace___rmatmul___xpu_int64 | RuntimeError: Long is not supported in oneDNN!
test_meta_xpu.py|test_dispatch_symbolic_meta_outplace_addbmm_xpu_int64 | RuntimeError: Long is not supported in oneDNN!
test_meta_xpu.py|test_dispatch_symbolic_meta_outplace_addmm_decomposed_xpu_int64 | RuntimeError: Long is not supported in oneDNN!
test_meta_xpu.py|test_dispatch_symbolic_meta_outplace_addmm_xpu_int64 | RuntimeError: Long is not supported in oneDNN!
test_meta_xpu.py|test_dispatch_symbolic_meta_outplace_addmv_xpu_int64 | RuntimeError: Long is not supported in oneDNN!
test_meta_xpu.py|test_dispatch_symbolic_meta_outplace_baddbmm_xpu_int64 | RuntimeError: Long is not supported in oneDNN!
test_meta_xpu.py|test_dispatch_symbolic_meta_outplace_bmm_xpu_int64 | RuntimeError: Long is not supported in oneDNN!
test_meta_xpu.py|test_dispatch_symbolic_meta_outplace_einsum_xpu_int64 | RuntimeError: Long is not supported in oneDNN!
test_meta_xpu.py|test_dispatch_symbolic_meta_outplace_linalg_multi_dot_xpu_int64 | RuntimeError: Long is not supported in oneDNN!
test_meta_xpu.py|test_dispatch_symbolic_meta_outplace_matmul_xpu_int64 | RuntimeError: Long is not supported in oneDNN!
test_meta_xpu.py|test_dispatch_symbolic_meta_outplace_mm_xpu_int64 | RuntimeError: Long is not supported in oneDNN!
test_meta_xpu.py|test_dispatch_symbolic_meta_outplace_mv_xpu_int64 | RuntimeError: Long is not supported in oneDNN!
test_meta_xpu.py|test_dispatch_symbolic_meta_outplace_nn_functional_bilinear_xpu_int64 | RuntimeError: Long is not supported in oneDNN!
test_meta_xpu.py|test_dispatch_symbolic_meta_outplace_nn_functional_conv1d_xpu_int64 | RuntimeError: Long is not supported in oneDNN!
test_meta_xpu.py|test_dispatch_symbolic_meta_outplace_nn_functional_conv2d_xpu_int64 | RuntimeError: Long is not supported in oneDNN!
test_meta_xpu.py|test_dispatch_symbolic_meta_outplace_nn_functional_conv3d_xpu_int64 | RuntimeError: Long is not supported in oneDNN!
test_meta_xpu.py|test_dispatch_symbolic_meta_outplace_nn_functional_conv_transpose1d_xpu_int64 | RuntimeError: Long is not supported in oneDNN!
test_meta_xpu.py|test_dispatch_symbolic_meta_outplace_nn_functional_conv_transpose2d_xpu_int64 | RuntimeError: Long is not supported in oneDNN!
test_meta_xpu.py|test_dispatch_symbolic_meta_outplace_nn_functional_conv_transpose3d_xpu_int64 | RuntimeError: Long is not supported in oneDNN!
test_meta_xpu.py|test_dispatch_symbolic_meta_outplace_tensordot_xpu_int64 | RuntimeError: Long is not supported in oneDNN!
test_meta_xpu.py|test_meta_inplace_addbmm_xpu_int64 | RuntimeError: Long is not supported in oneDNN!
test_meta_xpu.py|test_meta_inplace_addmm_decomposed_xpu_int64 | RuntimeError: Long is not supported in oneDNN!
test_meta_xpu.py|test_meta_inplace_addmm_xpu_int64 | RuntimeError: Long is not supported in oneDNN!
test_meta_xpu.py|test_meta_inplace_addmv_xpu_int64 | RuntimeError: Long is not supported in oneDNN!
test_meta_xpu.py|test_meta_inplace_baddbmm_xpu_int64 | RuntimeError: Long is not supported in oneDNN!
test_meta_xpu.py|test_meta_outplace___rmatmul___xpu_int64 | RuntimeError: Long is not supported in oneDNN!
test_meta_xpu.py|test_meta_outplace_addbmm_xpu_int64 | RuntimeError: Long is not supported in oneDNN!
test_meta_xpu.py|test_meta_outplace_addmm_decomposed_xpu_int64 | RuntimeError: Long is not supported in oneDNN!
test_meta_xpu.py|test_meta_outplace_addmm_xpu_int64 | RuntimeError: Long is not supported in oneDNN!
test_meta_xpu.py|test_meta_outplace_addmv_xpu_int64 | RuntimeError: Long is not supported in oneDNN!
test_meta_xpu.py|test_meta_outplace_baddbmm_xpu_int64 | RuntimeError: Long is not supported in oneDNN!
test_meta_xpu.py|test_meta_outplace_bmm_xpu_int64 | RuntimeError: Long is not supported in oneDNN!
test_meta_xpu.py|test_meta_outplace_einsum_xpu_int64 | RuntimeError: Long is not supported in oneDNN!
test_meta_xpu.py|test_meta_outplace_linalg_multi_dot_xpu_int64 | RuntimeError: Long is not supported in oneDNN!
test_meta_xpu.py|test_meta_outplace_matmul_xpu_int64 | RuntimeError: Long is not supported in oneDNN!
test_meta_xpu.py|test_meta_outplace_mm_xpu_int64 | RuntimeError: Long is not supported in oneDNN!
test_meta_xpu.py|test_meta_outplace_mv_xpu_int64 | RuntimeError: Long is not supported in oneDNN!
test_meta_xpu.py|test_meta_outplace_nn_functional_bilinear_xpu_int64 | RuntimeError: Long is not supported in oneDNN!
test_meta_xpu.py|test_meta_outplace_nn_functional_conv1d_xpu_int64 | RuntimeError: Long is not supported in oneDNN!
test_meta_xpu.py|test_meta_outplace_nn_functional_conv2d_xpu_int64 | RuntimeError: Long is not supported in oneDNN!
test_meta_xpu.py|test_meta_outplace_nn_functional_conv3d_xpu_int64 | RuntimeError: Long is not supported in oneDNN!
test_meta_xpu.py|test_meta_outplace_nn_functional_conv_transpose1d_xpu_int64 | RuntimeError: Long is not supported in oneDNN!
test_meta_xpu.py|test_meta_outplace_nn_functional_conv_transpose2d_xpu_int64 | RuntimeError: Long is not supported in oneDNN!
test_meta_xpu.py|test_meta_outplace_nn_functional_conv_transpose3d_xpu_int64 | RuntimeError: Long is not supported in oneDNN!
test_meta_xpu.py|test_meta_outplace_tensordot_xpu_int64 | RuntimeError: Long is not supported in oneDNN!
test_meta_xpu.py|test_dispatch_meta_outplace_nn_functional_conv_transpose2d_xpu_bfloat16 | RuntimeError: could not create a primitive descriptor for a deconvolution forward propagation primitive
test_meta_xpu.py|test_dispatch_meta_outplace_nn_functional_conv_transpose2d_xpu_complex | RuntimeError: could not create a primitive descriptor for a deconvolution forward propagation primitive
test_meta_xpu.py|test_dispatch_meta_outplace_nn_functional_conv_transpose2d_xpu_float | RuntimeError: could not create a primitive descriptor for a deconvolution forward propagation primitive
test_meta_xpu.py|test_dispatch_meta_outplace_nn_functional_conv_transpose3d_xpu_bfloat16 | RuntimeError: could not create a primitive descriptor for a deconvolution forward propagation primitive
test_meta_xpu.py|test_dispatch_meta_outplace_nn_functional_conv_transpose3d_xpu_complex | RuntimeError: could not create a primitive descriptor for a deconvolution forward propagation primitive
test_meta_xpu.py|test_dispatch_meta_outplace_nn_functional_conv_transpose3d_xpu_float | RuntimeError: could not create a primitive descriptor for a deconvolution forward propagation primitive
test_meta_xpu.py|test_dispatch_symbolic_meta_outplace_all_strides_nn_functional_conv_transpose2d_xpu_float32 | RuntimeError: could not create a primitive descriptor for a deconvolution forward propagation primitive
test_meta_xpu.py|test_dispatch_symbolic_meta_outplace_all_strides_nn_functional_conv_transpose3d_xpu_float32 | RuntimeError: could not create a primitive descriptor for a deconvolution forward propagation primitive
test_meta_xpu.py|test_dispatch_symbolic_meta_outplace_nn_functional_conv_transpose2d_xpu_bfloat16 | RuntimeError: could not create a primitive descriptor for a deconvolution forward propagation primitive
test_meta_xpu.py|test_dispatch_symbolic_meta_outplace_nn_functional_conv_transpose2d_xpu_complex | RuntimeError: could not create a primitive descriptor for a deconvolution forward propagation primitive
test_meta_xpu.py|test_dispatch_symbolic_meta_outplace_nn_functional_conv_transpose2d_xpu_float | RuntimeError: could not create a primitive descriptor for a deconvolution forward propagation primitive
test_meta_xpu.py|test_dispatch_symbolic_meta_outplace_nn_functional_conv_transpose3d_xpu_bfloat16 | RuntimeError: could not create a primitive descriptor for a deconvolution forward propagation primitive
test_meta_xpu.py|test_dispatch_symbolic_meta_outplace_nn_functional_conv_transpose3d_xpu_complex | RuntimeError: could not create a primitive descriptor for a deconvolution forward propagation primitive
test_meta_xpu.py|test_dispatch_symbolic_meta_outplace_nn_functional_conv_transpose3d_xpu_float | RuntimeError: could not create a primitive descriptor for a deconvolution forward propagation primitive
test_meta_xpu.py|test_meta_outplace_nn_functional_conv_transpose2d_xpu_bfloat16 | RuntimeError: could not create a primitive descriptor for a deconvolution forward propagation primitive
test_meta_xpu.py|test_meta_outplace_nn_functional_conv_transpose2d_xpu_complex | RuntimeError: could not create a primitive descriptor for a deconvolution forward propagation primitive
test_meta_xpu.py|test_meta_outplace_nn_functional_conv_transpose2d_xpu_float | RuntimeError: could not create a primitive descriptor for a deconvolution forward propagation primitive
test_meta_xpu.py|test_meta_outplace_nn_functional_conv_transpose3d_xpu_bfloat16 | RuntimeError: could not create a primitive descriptor for a deconvolution forward propagation primitive
test_meta_xpu.py|test_meta_outplace_nn_functional_conv_transpose3d_xpu_complex | RuntimeError: could not create a primitive descriptor for a deconvolution forward propagation primitive
test_meta_xpu.py|test_meta_outplace_nn_functional_conv_transpose3d_xpu_float | RuntimeError: could not create a primitive descriptor for a deconvolution forward propagation primitive
test_meta_xpu.py|test_dispatch_meta_outplace_vdot_xpu_complex | Not implemented, try these cases after implementing vdot
test_meta_xpu.py|test_dispatch_symbolic_meta_outplace_vdot_xpu_complex | Not implemented, try these cases after implementing vdot
test_meta_xpu.py|test_meta_outplace_vdot_xpu_complex | Not implemented, try these cases after implementing vdot
test_meta_xpu.py|test_dispatch_symbolic_meta_outplace_all_strides_narrow_copy_xpu_float32 | Unexpected success:
test_spectral_ops_xpu.py|test_cufft_plan_cache_xpu_float64 | CUDA specific case
test_decomp.py|test_comprehensive_baddbmm_xpu_float64 | AssertionError: Tensor-likes are not close! ; Exception: Tensor-likes are not close!
test_decomp.py|test_comprehensive_logspace_tensor_overload_xpu_int16 | AssertionError: Tensor-likes are not close! ; Exception: Tensor-likes are not close!
test_decomp.py|test_comprehensive_logspace_tensor_overload_xpu_int32 | AssertionError: Tensor-likes are not close! ; Exception: Tensor-likes are not close!
test_decomp.py|test_comprehensive_logspace_tensor_overload_xpu_int64 | AssertionError: Tensor-likes are not close! ; Exception: Tensor-likes are not close!
test_decomp.py|test_comprehensive_logspace_xpu_int16 | AssertionError: Tensor-likes are not close! ; Exception: Tensor-likes are not close!
test_decomp.py|test_comprehensive_logspace_xpu_int32 | AssertionError: Tensor-likes are not close! ; Exception: Tensor-likes are not close!
test_decomp.py|test_comprehensive_logspace_xpu_int64 | AssertionError: Tensor-likes are not close! ; Exception: Tensor-likes are not close!
test_decomp.py|test_comprehensive_nn_functional_conv_transpose2d_xpu_bfloat16 | RuntimeError: could not create a primitive descriptor for the deconvolution forward propagation primitive.
test_decomp.py|test_comprehensive_nn_functional_conv_transpose2d_xpu_complex128 | RuntimeError: could not create a primitive descriptor for the deconvolution forward propagation primitive.
test_decomp.py|test_comprehensive_nn_functional_conv_transpose2d_xpu_complex32 | RuntimeError: could not create a primitive descriptor for the deconvolution forward propagation primitive.
test_decomp.py|test_comprehensive_nn_functional_conv_transpose2d_xpu_complex64 | RuntimeError: could not create a primitive descriptor for the deconvolution forward propagation primitive.
test_decomp.py|test_comprehensive_nn_functional_conv_transpose2d_xpu_float16 | RuntimeError: could not create a primitive descriptor for the deconvolution forward propagation primitive.
test_decomp.py|test_comprehensive_nn_functional_conv_transpose2d_xpu_float32 | RuntimeError: could not create a primitive descriptor for the deconvolution forward propagation primitive.
test_decomp.py|test_comprehensive_nn_functional_conv_transpose2d_xpu_float64 | RuntimeError: could not create a primitive descriptor for the deconvolution forward propagation primitive.
test_decomp.py|test_comprehensive_nn_functional_conv_transpose3d_xpu_bfloat16 | RuntimeError: could not create a primitive descriptor for the deconvolution forward propagation primitive.
test_decomp.py|test_comprehensive_nn_functional_conv_transpose3d_xpu_complex128 | RuntimeError: could not create a primitive descriptor for the deconvolution forward propagation primitive.
test_decomp.py|test_comprehensive_nn_functional_conv_transpose3d_xpu_complex32 | RuntimeError: could not create a primitive descriptor for the deconvolution forward propagation primitive.
test_decomp.py|test_comprehensive_nn_functional_conv_transpose3d_xpu_complex64 | RuntimeError: could not create a primitive descriptor for the deconvolution forward propagation primitive.
test_decomp.py|test_comprehensive_nn_functional_conv_transpose3d_xpu_float16 | RuntimeError: could not create a primitive descriptor for the deconvolution forward propagation primitive.
test_decomp.py|test_comprehensive_nn_functional_conv_transpose3d_xpu_float32 | RuntimeError: could not create a primitive descriptor for the deconvolution forward propagation primitive.
test_decomp.py|test_comprehensive_nn_functional_conv_transpose3d_xpu_float64 | RuntimeError: could not create a primitive descriptor for the deconvolution forward propagation primitive.
test_decomp.py|test_comprehensive_nn_functional_instance_norm_xpu_float64 | AssertionError: Tensor-likes are not close! ; Exception: Tensor-likes are not close!
test_decomp.py|test_comprehensive_nn_functional_nll_loss_xpu_float16 | RuntimeError: Difference from float64 is larger with decomposition nll_loss_forward.default than original on output 0.
test_decomp.py|test_comprehensive_nn_functional_pad_reflect_xpu_bfloat16 | RuntimeError: Difference from float64 is larger with decomposition nll_loss_forward.default than original on output 0.
test_decomp.py|test_comprehensive_torch_ops_aten__flash_attention_forward_xpu_float16 | NotImplementedError: Could not run 'aten::_flash_attention_forward' with arguments from the 'CPU' backend.
test_decomp.py|test_comprehensive_vdot_xpu_complex128 | AssertionError: Scalars are not close! ; Exception: Scalars are not close!
test_decomp.py|test_comprehensive_vdot_xpu_complex64 | AssertionError: Scalars are not close! ; Exception: Scalars are not close!
test_decomp.py|test_quick_addmm_xpu_float64 | AssertionError: Tensor-likes are not close! ; Exception: Tensor-likes are not close!
test_decomp.py|test_quick_baddbmm_xpu_float64 | AssertionError: Tensor-likes are not close! ; Exception: Tensor-likes are not close!
test_decomp.py|test_quick_core_backward_baddbmm_xpu_float64 | AssertionError: Tensor-likes are not close! ; Exception: Tensor-likes are not close!
test_decomp.py|test_quick_core_backward_mv_xpu_float64 | Exception: Jacobian mismatch for output 0 with respect to input 0
test_decomp.py|test_quick_logspace_tensor_overload_xpu_int16 | AssertionError: Tensor-likes are not equal! ; Exception: Tensor-likes are not equal!
test_decomp.py|test_quick_logspace_tensor_overload_xpu_int32 | AssertionError: Tensor-likes are not equal! ; Exception: Tensor-likes are not equal!
test_decomp.py|test_quick_logspace_tensor_overload_xpu_int64 | AssertionError: Tensor-likes are not equal! ; Exception: Tensor-likes are not equal!
test_decomp.py|test_quick_logspace_xpu_int16 | AssertionError: Tensor-likes are not equal! ; Exception: Tensor-likes are not equal!
test_decomp.py|test_quick_logspace_xpu_int32 | AssertionError: Tensor-likes are not equal! ; Exception: Tensor-likes are not equal!
test_decomp.py|test_quick_logspace_xpu_int64 | AssertionError: Tensor-likes are not equal! ; Exception: Tensor-likes are not equal!
test_decomp.py|test_quick_vdot_xpu_complex128 | AssertionError: Scalars are not close! ; Exception: Scalars are not close!
test_decomp.py|test_quick_vdot_xpu_complex64 | AssertionError: Scalars are not close! ; Exception: Scalars are not close!
test_decomp.py|test_exponential_non_inf_xpu | AssertionError: Tensor-likes are not close!
test_decomp.py|test_aten_core_operators | RuntimeError: I got this output for HasDecompTest.test_aten_core_operators:
test_decomp.py|test_has_decomposition | RuntimeError: I got this output for HasDecompTest.test_aten_core_operators:
test_decomp.py|test_comprehensive_diff_xpu_complex128 | AssertionError: Tensor-likes are not close!
test_decomp.py|test_comprehensive_ormqr_xpu_complex128 | AssertionError: Tensor-likes are not close!
test_decomp.py|test_quick_var_mean_xpu_float64 | AssertionError: Tensor-likes are not close!
test_decomp.py|test_comprehensive_diff_xpu_complex64 | AssertionError: Tensor-likes are not close!
test_decomp.py|test_comprehensive_ormqr_xpu_complex64 | AssertionError: Tensor-likes are not close!
test_decomp.py|test_quick_mean_xpu_complex128 | AssertionError: Tensor-likes are not close!
test_decomp.py|test_comprehensive_grid_sampler_2d_xpu_bfloat16 | AssertionError: Tensor-likes are not close!
